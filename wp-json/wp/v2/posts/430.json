{"id":430,"date":"2019-11-04T01:23:00","date_gmt":"2019-11-04T01:23:00","guid":{"rendered":"https:\/\/rikkeisoft.com\/2019\/11\/04\/google-just-got-better-at-understanding-your-trickiest-searches\/"},"modified":"2021-12-03T08:15:18","modified_gmt":"2021-12-03T08:15:18","slug":"google-just-got-better-at-understanding-your-trickiest-searches","status":"publish","type":"post","link":"https:\/\/rikkeisoft.com\/lastest-thinking\/430\/google-just-got-better-at-understanding-your-trickiest-searches\/","title":{"rendered":"Google just got better at understanding your trickiest searches"},"content":{"rendered":"<p><strong><span style=\"font-family:Lucida Sans Unicode,Lucida Grande,sans-serif;\">A new machine learning algorithm is helping Google tell which words in queries matter most &#8211; and how they relate to each other.<\/span><\/strong><\/p>\n<p>&nbsp;<\/p>\n<p><span style=\"font-size:12px;\"><span style=\"font-family:Lucida Sans Unicode,Lucida Grande,sans-serif;\"><img loading=\"lazy\" alt=\"\" height=\"527\" src=\"https:\/\/rikkeisoft.com\/wp-content\/themes\/main\/assets\/ckfinder\/images\/p-1-google-just-got-better-at-understanding-your-trickiest-searches.jpg\" width=\"937\" \/><\/span><\/span><\/p>\n<p>&nbsp;<\/p>\n<p><span style=\"font-family:Lucida Sans Unicode,Lucida Grande,sans-serif;\">For Google&rsquo;s namesake search engine, delivering the right results is about understanding what people are asking for. And understanding that involves zeroing in on the meaningful keywords in a search query and ignoring the rest. Words like &ldquo;a&rdquo; and &ldquo;the,&rdquo; for instance, can generally be safely ignored.&nbsp;<\/span><\/p>\n<p>&nbsp;<\/p>\n<p><span style=\"font-family:Lucida Sans Unicode,Lucida Grande,sans-serif;\">The problem is that there are lots of searches where it&rsquo;s difficult for even a search engine as smart as Google to know how the words relate to each other and which ones matter. One example the company provides: If a user searches for &ldquo;can you get medicine for someone pharmacy,&rdquo; the &ldquo;someone&rdquo; is absolutely critical, since it&rsquo;s shorthand for &ldquo;someone other than myself.&rdquo; A person would likely infer that that; a traditional search algorithm, not so much.<\/span><\/p>\n<p>&nbsp;<\/p>\n<p><span style=\"font-family:Lucida Sans Unicode,Lucida Grande,sans-serif;\">But now Google is rolling out an update to its English-language search engine designed to give it a deeper understanding of such subtle queries, which will let it deliver more relevant results. For the above search, results are now topped with a &ldquo;featured snippet&rdquo; involving the specific issue of picking up another person&rsquo;s prescription. (Previously, the snippet involved prescriptions but failed to address the specific gist of the query.)<\/span><\/p>\n<p>&nbsp;<\/p>\n<p><span style=\"font-family:Lucida Sans Unicode,Lucida Grande,sans-serif;\">I attended a press preview at Google headquarters earlier this week, where some of company&rsquo;s search executives showed examples of the new algorithm&rsquo;s improved results and explained the new technology that went into them. And they set the bar high for expectations; VP of search Pandu Nayak called them &ldquo;the single biggest change we&rsquo;ve had in the last five years and perhaps one of the biggest since the beginning of the company.&rdquo;<\/span><\/p>\n<p>&nbsp;<\/p>\n<p style=\"text-align:center\"><img loading=\"lazy\" alt=\"\" height=\"347\" src=\"https:\/\/rikkeisoft.com\/wp-content\/themes\/main\/assets\/ckfinder\/images\/google%201.png\" width=\"596\" \/><\/p>\n<p>&nbsp;<\/p>\n<p><span style=\"font-size:20px;\"><span style=\"font-family:Tahoma,Geneva,sans-serif;\"><strong>BERT AT WORK<\/strong><\/span><\/span><\/p>\n<p>&nbsp;<\/p>\n<p><span style=\"font-family:Tahoma,Geneva,sans-serif;\">Under the service, the new improvements leverage a technology developed at Google called&nbsp;<a href=\"https:\/\/www.wired.com\/story\/computers-are-learning-to-read-but-theyre-still-not-so-smart\/\" rel=\"noopener noreferrer\" target=\"_blank\">BERT<\/a>, which stands for Bidirectional Encoder Representations from Transformers. We non-AI scientists don&rsquo;t have to worry about what encoders, representations, and transformers are. But the gist of the idea is that BERT trains machine language algorithms by feeding them chunks of text that have some of the words removed. The algorithm&rsquo;s challenge is to guess the missing words&mdash;which turns out to be a game that computers are good at playing, and an effective way to efficiently train an algorithm to understand text. From a comprehension standpoint, it helps &ldquo;turn keyword-ese into language,&rdquo; said&nbsp;<a href=\"https:\/\/www.fastcompany.com\/90241011\/this-man-has-helped-shape-google-search-almost-from-the-start\" rel=\"noopener noreferrer\" target=\"_blank\">Google search chief Ben Gomes<\/a>.<\/span><\/p>\n<p>&nbsp;<\/p>\n<p><span style=\"font-family:Tahoma,Geneva,sans-serif;\">&ldquo;The more text, the better the understanding,&rdquo; said Google senior VP of research Jeff Dean&mdash;and fortunately, there&rsquo;s no shortage of written material out there that Google can pour into BERT. (And oh, the &ldquo;Bidirectional&rdquo; part of the acronym references the fact that this technique moves away from the more conventional practice of analyzing text a word at a time from left to right.)<\/span><\/p>\n<p>&nbsp;<\/p>\n<p><span style=\"font-family:Tahoma,Geneva,sans-serif;\">Using&nbsp;<a href=\"https:\/\/cloud.google.com\/blog\/products\/ai-machine-learning\/googles-scalable-supercomputers-for-machine-learning-cloud-tpu-pods-are-now-publicly-available-in-beta\" rel=\"noopener noreferrer\" target=\"_blank\">supercomputers it designed itself to train machine learning models<\/a>, Google is applying BERT to give its search algorithm a deeper understanding of search queries and web pages that contain relevant information. Other tech companies have embraced BERT and are using their own variants for a variety of purposes: Facebook, for instance, is using a version called RoBERTa in&nbsp;<a href=\"https:\/\/www.fastcompany.com\/90398860\/facebook-is-teaching-computers-the-fine-art-of-conversation\" rel=\"noopener noreferrer\" target=\"_blank\">chatbot research<\/a>. But these new Google search tweaks are an early instance of BERT coming out of the lab and improving one of the world&rsquo;s most widely used services.<\/span><\/p>\n<p>&nbsp;<\/p>\n<p><span style=\"font-family:Tahoma,Geneva,sans-serif;\">The new BERT training is only one of an array of elements that Google calls upon to choose results for any given search; the company says that it will come into play in around 1 out of 10 searches. But that 10% should include some of the ones that were most likely to stump Google in the past, such as &ldquo;How old was Taylor Swift when Kanye went onstage?&rdquo; and &ldquo;Do estheticians stand a lot at work?&rdquo;<\/span><\/p>\n<p>&nbsp;<\/p>\n<p><span style=\"font-family:Tahoma,Geneva,sans-serif;\">Under the service, the new improvements leverage a technology developed at Google called&nbsp;<a href=\"https:\/\/www.wired.com\/story\/computers-are-learning-to-read-but-theyre-still-not-so-smart\/\" rel=\"noopener noreferrer\" target=\"_blank\">BERT<\/a>, which stands for Bidirectional Encoder Representations from Transformers. We non-AI scientists don&rsquo;t have to worry about what encoders, representations, and transformers are. But the gist of the idea is that BERT trains machine language algorithms by feeding them chunks of text that have some of the words removed. The algorithm&rsquo;s challenge is to guess the missing words&mdash;which turns out to be a game that computers are good at playing, and an effective way to efficiently train an algorithm to understand text. From a comprehension standpoint, it helps &ldquo;turn keyword-ese into language,&rdquo; said&nbsp;<a href=\"https:\/\/www.fastcompany.com\/90241011\/this-man-has-helped-shape-google-search-almost-from-the-start\" rel=\"noopener noreferrer\" target=\"_blank\">Google search chief Ben Gomes<\/a>.<\/span><\/p>\n<p>&nbsp;<\/p>\n<p><span style=\"font-family:Tahoma,Geneva,sans-serif;\">&ldquo;The more text, the better the understanding,&rdquo; said Google senior VP of research Jeff Dean&mdash;and fortunately, there&rsquo;s no shortage of written material out there that Google can pour into BERT. (And oh, the &ldquo;Bidirectional&rdquo; part of the acronym references the fact that this technique moves away from the more conventional practice of analyzing text a word at a time from left to right.)<\/span><\/p>\n<p>&nbsp;<\/p>\n<p><span style=\"font-family:Tahoma,Geneva,sans-serif;\">Using&nbsp;<a href=\"https:\/\/cloud.google.com\/blog\/products\/ai-machine-learning\/googles-scalable-supercomputers-for-machine-learning-cloud-tpu-pods-are-now-publicly-available-in-beta\" rel=\"noopener noreferrer\" target=\"_blank\">supercomputers it designed itself to train machine learning models<\/a>, Google is applying BERT to give its search algorithm a deeper understanding of search queries and web pages that contain relevant information. Other tech companies have embraced BERT and are using their own variants for a variety of purposes: Facebook, for instance, is using a version called RoBERTa in&nbsp;<a href=\"https:\/\/www.fastcompany.com\/90398860\/facebook-is-teaching-computers-the-fine-art-of-conversation\" rel=\"noopener noreferrer\" target=\"_blank\">chatbot research<\/a>. But these new Google search tweaks are an early instance of BERT coming out of the lab and improving one of the world&rsquo;s most widely used services.<\/span><\/p>\n<p>&nbsp;<\/p>\n<p><span style=\"font-family:Tahoma,Geneva,sans-serif;\">The new BERT training is only one of an array of elements that Google calls upon to choose results for any given search; the company says that it will come into play in around 1 out of 10 searches. But that 10% should include some of the ones that were most likely to stump Google in the past, such as &ldquo;How old was Taylor Swift when Kanye went onstage?&rdquo; and &ldquo;Do estheticians stand a lot at work?&rdquo;<\/span>.&nbsp;<\/p>\n<p>&nbsp;<\/p>\n<p style=\"text-align:center\"><img loading=\"lazy\" alt=\"\" height=\"317\" src=\"https:\/\/rikkeisoft.com\/wp-content\/themes\/main\/assets\/ckfinder\/images\/google%202.png\" width=\"576\" \/><\/p>\n<p><span style=\"font-family:Tahoma,Geneva,sans-serif;\">In the end, BERT probably won&rsquo;t have as obvious an impact on results as past Google milestones such as&nbsp;<a href=\"https:\/\/searchengineland.com\/google-20-google-universal-search-11232\" rel=\"noopener noreferrer\" target=\"_blank\">universal search<\/a>&nbsp;and&nbsp;<a href=\"http:\/\/techland.time.com\/2012\/05\/16\/the-knowledge-graph-googles-next-frontier-for-search\/\" rel=\"noopener noreferrer\" target=\"_blank\">the knowledge graph<\/a>, both of which fundamentally revised the presentation of search results in ways you couldn&rsquo;t help but notice. With the addition of BERT, results still look the same; if BERT makes them better, you&rsquo;ll benefit&mdash;but you&rsquo;ll never know that they would have been inferior in its absence.<\/span><\/p>\n<p>&nbsp;<\/p>\n<p><span style=\"font-family:Tahoma,Geneva,sans-serif;\">And even then, Nayak cheerfully acknowledges that there are instances when the BERT-infused search results are worse than the old ones. At the press event, he showed a sample: When asked &ldquo;What state is south of Nebraska?&rdquo; the BERT result involved the neighborhood of South Nebraska in Tampa, Florida, and was not just less relevant than its non-BERT predecessor but downright useless. But Google&rsquo;s testing shows such instances are rare enough that using BERT provides a clear overall advantage, which should increase as the company tweaks the technology over time.<\/span><\/p>\n<p>&nbsp;<\/p>\n<p><span style=\"font-family:Tahoma,Geneva,sans-serif;\">&ldquo;BERT is not like some magic bullet that solves all problems, but it does solve a lot of problem areas,&rdquo; said Nayak. &ldquo;There&rsquo;s still more work to do.&rdquo;<\/span><\/p>\n<p>&nbsp;<\/p>\n<p><strong>By:<\/strong><em>&nbsp;<span style=\"font-size:12px;\"><strong><a href=\"https:\/\/www.fastcompany.com\/user\/harry-mccracken\">HARRY MCCRACKEN<\/a><\/strong><\/span><\/em><\/p>\n<p><strong>Source:<\/strong>&nbsp;<a href=\"https:\/\/www.fastcompany.com\/90422132\/google-just-got-better-at-understanding-your-trickiest-searches\"><em>https:\/\/www.fastcompany.com\/90422132\/google-just-got-better-at-understanding-your-trickiest-searches<\/em><\/a><\/p>\n","protected":false},"excerpt":{"rendered":"<p>A new machine learning algorithm is helping Google tell which words in queries matter most &#8211; and how they relate to each other. &nbsp; &nbsp; For Google&rsquo;s namesake search engine, delivering the right results is about understanding what people are asking for. And understanding that involves zeroing in on the meaningful keywords in a search [&hellip;]<\/p>\n","protected":false},"author":5,"featured_media":431,"comment_status":"closed","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[17],"tags":[],"yst_prominent_words":[],"yoast_head":"<!-- This site is optimized with the Yoast SEO Premium plugin v14.0.4 - https:\/\/yoast.com\/wordpress\/plugins\/seo\/ -->\n<title>Google just got better at understanding your trickiest searches - \u30d9\u30c8\u30ca\u30e0\u30aa\u30d5\u30b7\u30e7\u30a2\u958b\u767a\u4f01\u696d | \u30ea\u30c3\u30b1\u30a4\u30bd\u30d5\u30c8<\/title>\n<meta name=\"robots\" content=\"index, follow\" \/>\n<meta name=\"googlebot\" content=\"index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1\" \/>\n<meta name=\"bingbot\" content=\"index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1\" \/>\n<link rel=\"canonical\" href=\"https:\/\/rikkeisoft.com\/lastest-thinking\/430\/google-just-got-better-at-understanding-your-trickiest-searches\/\" \/>\n<meta property=\"og:locale\" content=\"vi_VN\" \/>\n<meta property=\"og:type\" content=\"article\" \/>\n<meta property=\"og:title\" content=\"Google just got better at understanding your trickiest searches - \u30d9\u30c8\u30ca\u30e0\u30aa\u30d5\u30b7\u30e7\u30a2\u958b\u767a\u4f01\u696d | \u30ea\u30c3\u30b1\u30a4\u30bd\u30d5\u30c8\" \/>\n<meta property=\"og:description\" content=\"A new machine learning algorithm is helping Google tell which words in queries matter most &#8211; and how they relate to each other. &nbsp; &nbsp; For Google&rsquo;s namesake search engine, delivering the right results is about understanding what people are asking for. And understanding that involves zeroing in on the meaningful keywords in a search [&hellip;]\" \/>\n<meta property=\"og:url\" content=\"https:\/\/rikkeisoft.com\/lastest-thinking\/430\/google-just-got-better-at-understanding-your-trickiest-searches\/\" \/>\n<meta property=\"og:site_name\" content=\"\u30d9\u30c8\u30ca\u30e0\u30aa\u30d5\u30b7\u30e7\u30a2\u958b\u767a\u4f01\u696d | \u30ea\u30c3\u30b1\u30a4\u30bd\u30d5\u30c8\" \/>\n<meta property=\"article:published_time\" content=\"2019-11-04T01:23:00+00:00\" \/>\n<meta property=\"article:modified_time\" content=\"2021-12-03T08:15:18+00:00\" \/>\n<meta property=\"og:image\" content=\"https:\/\/rikkeisoft.com\/wp-content\/uploads\/2021\/12\/google-just-got-better-at-understanding-your-trickiest-searches-1.jpg\" \/>\n\t<meta property=\"og:image:width\" content=\"640\" \/>\n\t<meta property=\"og:image:height\" content=\"304\" \/>\n<meta name=\"twitter:card\" content=\"summary_large_image\" \/>\n<script type=\"application\/ld+json\" class=\"yoast-schema-graph\">{\"@context\":\"https:\/\/schema.org\",\"@graph\":[{\"@type\":\"WebSite\",\"@id\":\"https:\/\/rikkeisoft.com\/#website\",\"url\":\"https:\/\/rikkeisoft.com\/\",\"name\":\"\\u30d9\\u30c8\\u30ca\\u30e0\\u30aa\\u30d5\\u30b7\\u30e7\\u30a2\\u958b\\u767a\\u4f01\\u696d | \\u30ea\\u30c3\\u30b1\\u30a4\\u30bd\\u30d5\\u30c8\",\"description\":\"\\u30d9\\u30c8\\u30ca\\u30e0\\u30aa\\u30d5\\u30b7\\u30e7\\u30a2\\u958b\\u767a\\u4f01\\u696d | \\u30ea\\u30c3\\u30b1\\u30a4\\u30bd\\u30d5\\u30c8\",\"potentialAction\":[{\"@type\":\"SearchAction\",\"target\":\"https:\/\/rikkeisoft.com\/?s={search_term_string}\",\"query-input\":\"required name=search_term_string\"}],\"inLanguage\":\"vi\"},{\"@type\":\"ImageObject\",\"@id\":\"https:\/\/rikkeisoft.com\/lastest-thinking\/430\/google-just-got-better-at-understanding-your-trickiest-searches\/#primaryimage\",\"inLanguage\":\"vi\",\"url\":\"https:\/\/rikkeisoft.com\/wp-content\/uploads\/2021\/12\/google-just-got-better-at-understanding-your-trickiest-searches-1.jpg\",\"width\":640,\"height\":304},{\"@type\":\"WebPage\",\"@id\":\"https:\/\/rikkeisoft.com\/lastest-thinking\/430\/google-just-got-better-at-understanding-your-trickiest-searches\/#webpage\",\"url\":\"https:\/\/rikkeisoft.com\/lastest-thinking\/430\/google-just-got-better-at-understanding-your-trickiest-searches\/\",\"name\":\"Google just got better at understanding your trickiest searches - \\u30d9\\u30c8\\u30ca\\u30e0\\u30aa\\u30d5\\u30b7\\u30e7\\u30a2\\u958b\\u767a\\u4f01\\u696d | \\u30ea\\u30c3\\u30b1\\u30a4\\u30bd\\u30d5\\u30c8\",\"isPartOf\":{\"@id\":\"https:\/\/rikkeisoft.com\/#website\"},\"primaryImageOfPage\":{\"@id\":\"https:\/\/rikkeisoft.com\/lastest-thinking\/430\/google-just-got-better-at-understanding-your-trickiest-searches\/#primaryimage\"},\"datePublished\":\"2019-11-04T01:23:00+00:00\",\"dateModified\":\"2021-12-03T08:15:18+00:00\",\"author\":{\"@id\":\"https:\/\/rikkeisoft.com\/#\/schema\/person\/0194e8b71dafb06076827553082af72b\"},\"inLanguage\":\"vi\",\"potentialAction\":[{\"@type\":\"ReadAction\",\"target\":[\"https:\/\/rikkeisoft.com\/lastest-thinking\/430\/google-just-got-better-at-understanding-your-trickiest-searches\/\"]}]},{\"@type\":[\"Person\"],\"@id\":\"https:\/\/rikkeisoft.com\/#\/schema\/person\/0194e8b71dafb06076827553082af72b\",\"name\":\"chitv@rikkeisoft.com\",\"image\":{\"@type\":\"ImageObject\",\"@id\":\"https:\/\/rikkeisoft.com\/#personlogo\",\"inLanguage\":\"vi\",\"url\":\"https:\/\/secure.gravatar.com\/avatar\/7c746addd5d1710efac023ebbd6f16ff?s=96&d=mm&r=g\",\"caption\":\"chitv@rikkeisoft.com\"}}]}<\/script>\n<!-- \/ Yoast SEO Premium plugin. -->","_links":{"self":[{"href":"https:\/\/rikkeisoft.com\/wp-json\/wp\/v2\/posts\/430"}],"collection":[{"href":"https:\/\/rikkeisoft.com\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"https:\/\/rikkeisoft.com\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"https:\/\/rikkeisoft.com\/wp-json\/wp\/v2\/users\/5"}],"replies":[{"embeddable":true,"href":"https:\/\/rikkeisoft.com\/wp-json\/wp\/v2\/comments?post=430"}],"version-history":[{"count":1,"href":"https:\/\/rikkeisoft.com\/wp-json\/wp\/v2\/posts\/430\/revisions"}],"predecessor-version":[{"id":690,"href":"https:\/\/rikkeisoft.com\/wp-json\/wp\/v2\/posts\/430\/revisions\/690"}],"wp:featuredmedia":[{"embeddable":true,"href":"https:\/\/rikkeisoft.com\/wp-json\/wp\/v2\/media\/431"}],"wp:attachment":[{"href":"https:\/\/rikkeisoft.com\/wp-json\/wp\/v2\/media?parent=430"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https:\/\/rikkeisoft.com\/wp-json\/wp\/v2\/categories?post=430"},{"taxonomy":"post_tag","embeddable":true,"href":"https:\/\/rikkeisoft.com\/wp-json\/wp\/v2\/tags?post=430"},{"taxonomy":"yst_prominent_words","embeddable":true,"href":"https:\/\/rikkeisoft.com\/wp-json\/wp\/v2\/yst_prominent_words?post=430"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}